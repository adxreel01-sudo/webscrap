PRODUCT FIELD EXTRACTION

(with explanation + implementation)

ğŸ¯ Goal (lock this)

From validated product URLs only, extract clean, structured product data
ready to match Schema v1.0.

You already did the hard parts (URL discovery + classification).
Now we extract data carefully.

ğŸ§  HOW WE WILL EXTRACT (IMPORTANT STRATEGY)

Because your site is Shopify, we use this order:

ğŸ¥‡ Method 1 â€” Shopify Product JSON (BEST & STABLE)

For any product URL:

https://site.com/products/slug


We fetch:

https://site.com/products/slug.js


Why this is best:

No HTML parsing issues

Gives name, price, images, variants

Less likely to break on UI changes

ğŸ¥ˆ Method 2 â€” HTML fallback

Used only if .js fails.

ğŸ“¥ INPUT & ğŸ“¤ OUTPUT
Input
scraper/output/validProductUrls.json

Output (this milestone)
scraper/output/productsRaw.json


-------------------------------------

â€” NORMALIZE + UPSERT INTO MONGODB
ğŸ¯ Goal (very clear)

Take productsRaw.json â†’ normalize it â†’ upsert into MongoDB
So:

No duplicates

Existing products update

New products insert

After this:

Your API will return scraped products

This is the point where CEO can see live data

ğŸ§  WHAT â€œUPSERTâ€ MEANS (IMPORTANT)

Upsert = Update OR Insert

Logic:

If (companyId + sourceUrl) exists â†’ UPDATE

If not â†’ INSERT

This matches the unique index you already created.