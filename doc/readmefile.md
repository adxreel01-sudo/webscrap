FINAL TARGET ARCHITECTURE (WHAT YOU SHOULD RUN)
USER
 ‚îú‚îÄ enters website
 ‚îÇ   ‚îî‚îÄ POST /api/company/scrape
 ‚îÇ        ‚îú‚îÄ Axios scrape
 ‚îÇ        ‚îú‚îÄ Deep pages (/about, /contact)
 ‚îÇ        ‚îú‚îÄ Playwright fallback (if needed)
 ‚îÇ        ‚îî‚îÄ Save Company (auto-fill)
 ‚îÇ
 ‚îî‚îÄ clicks "Scrape Products"
      ‚îî‚îÄ POST /api/company/:id/scrape-products
           ‚îú‚îÄ Discovery pipeline
           ‚îú‚îÄ Classification
           ‚îú‚îÄ Platform-aware extraction
           ‚îú‚îÄ Diff detection
           ‚îî‚îÄ DB upsert
           
CRON (weekly)
 ‚îî‚îÄ Re-run product scrape ONLY for active companies
     ‚îî‚îÄ Update changed products only

REQUIREMENT 1: AUTO-FILL COMPANY INFO (FIX)
Current problem

scr/controllers/company.controller.js:

Axios only

Homepage only

Fails on Titan, Bewakoof, JS-heavy sites

What to do (NO REWRITE, JUST EXTEND)
Add 2-layer fallback

Axios + Cheerio (fast)

Playwright (only if data quality is bad)

Data quality rule (STRICT)
name exists
AND about.length >= 50


If not ‚Üí fallback.

Result

CakeToppers ‚Üí Axios works

Titan ‚Üí Playwright required

Bewakoof ‚Üí Playwright required

üëâ This matches your mock companies perfectly.

REQUIREMENT 2: PRODUCT SCRAPE ON BUTTON CLICK
Current situation

Product scraping exists

BUT it runs via index.js + env vars

Not API-driven

What to add (MINIMAL CHANGE)
New API
POST /api/company/:companyId/scrape-products


Controller logic:

1. Load company from DB
2. Run discovery pipeline
3. Extract products
4. Upsert products
5. Return count


You already have all underlying code.
This is just orchestration.

REQUIREMENT 3: WEEKLY AUTO UPDATE (EFFICIENT)
You already have

Cron scheduler ‚úîÔ∏è

Active company filter ‚úîÔ∏è

Upsert logic ‚úîÔ∏è

What‚Äôs missing: CHANGE DETECTION

Right now:

Every scrape overwrites blindly

What you SHOULD do
Add product fingerprint

Before upsert, compute:

hash = sha1(
  name +
  price +
  images.join() +
  variants.join()
)


Store:

contentHash


During weekly scrape:

If hash unchanged ‚Üí skip DB write

If changed ‚Üí update + lastScrapedAt

This gives you:

Faster cron

Less DB load

Accurate ‚Äúupdated products‚Äù

HOW YOUR MOCK COMPANIES FIT PERFECTLY
Company	Platform	Expected behavior
CakeToppers	Shopify	Sitemap + Shopify JSON (easy)
Titan	Custom JS	Playwright fallback needed
Bewakoof	Shopify + JS	Shopify JSON + pagination

Your system is correctly designed for this ‚Äî it just needs:

fallback logic

unification

quality guards

WHAT I WOULD DO NEXT (ORDER MATTERS)

1Ô∏è‚É£ Refactor company scraper into layered strategy
2Ô∏è‚É£ Add API trigger for product pipeline
3Ô∏è‚É£ Add contentHash-based updates
4Ô∏è‚É£ Merge cron + API pipeline logic (single source)
5Ô∏è‚É£ Optional: proxy + stealth later (only if scale grows)

IMPORTANT TRUTH (NO SUGAR)

You CANNOT get perfect data for every site

Titan/Bewakoof WILL block Axios sometimes

Playwright is non-negotiable for real brands

Your architecture is already better than 90% scrapers online

If you want, next I can:

üîß Modify your exact company.controller.js (line-by-line)

üß† Design product diff logic

üöÄ Turn this into production SaaS-ready flow

üìä Define scrape status + monitoring